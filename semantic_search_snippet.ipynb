{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# For token tracking\n",
    "from langchain.callbacks import get_openai_callback # For tracking LLM calls\n",
    "from num_tokens_from_string import num_tokens_from_string # For tracking embedding\n",
    "\n",
    "# For document loading\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# For splitting document into chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# For embedding\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# For vector store\n",
    "import weaviate\n",
    "from langchain.vectorstores import Weaviate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load text files from file directory and split into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text files from folder\n",
    "loader = DirectoryLoader('./documents', glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "# split into chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, length_function=len\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring OpenAI Key\n",
    "os.environ[\"OPENAI_API_KEY\"]= \"\"\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Vector Store Instance\n",
    "\n",
    "I have created the schema in weaviate_vectorstore.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "# Set-Up Weaviate (done in weaviate_vectorstore.py)\n",
    "vectorstore = Weaviate(client, \"Paragraph\", \"content\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_meta_pair = []\n",
    "for doc in docs:\n",
    "    text_meta_pair.append((doc.page_content, doc.metadata))\n",
    "\n",
    "texts, meta = zip(*text_meta_pair)\n",
    "texts = list(texts)\n",
    "meta = list(meta)\n",
    "vectorstore.add_texts(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me about the iPhone10\"\n",
    "response = vectorstore.similarity_search(query)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.page_content)\n",
    "    print(\"*\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
